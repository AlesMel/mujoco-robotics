# ğŸ¤– MuJoCo Robot â€” UR Arm RL Environments

Modular reinforcement-learning environments for **UR5e** and **UR3e** robot arms
in [MuJoCo](https://mujoco.readthedocs.io/), with [Gymnasium](https://gymnasium.farama.org/)
wrappers for training and keyboard/gamepad teleop for interactive testing.

<p align="center">
  <img src="docs/images/reach_ur5e.png" alt="UR5e Reach Environment" width="100%"/>
</p>
<p align="center"><em>UR5e reach task â€” top, side, and end-effector camera views</em></p>

---

## ğŸ“ Project Structure

```
mujoco-robot/
â”œâ”€â”€ src/mujoco_robot/               # Main Python package
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ robots/                     # Robot models & configuration
â”‚   â”‚   â”œâ”€â”€ configs.py              # RobotConfig dataclass + registry
â”‚   â”‚   â”œâ”€â”€ ur5e.xml                # UR5e MJCF (Menagerie OBJ meshes)
â”‚   â”‚   â”œâ”€â”€ ur3e.xml                # UR3e MJCF (scaled UR5e meshes)
â”‚   â”‚   â””â”€â”€ assets/ur5e/            # 20 OBJ mesh files
â”‚   â”œâ”€â”€ core/                       # Reusable engine modules
â”‚   â”‚   â”œâ”€â”€ ik_controller.py        # Damped-least-squares IK solver
â”‚   â”‚   â”œâ”€â”€ collision.py            # Self-collision detector
â”‚   â”‚   â””â”€â”€ xml_builder.py          # MJCF XML injection utilities
â”‚   â”œâ”€â”€ envs/                       # Gymnasium-ready environments
â”‚   â”‚   â”œâ”€â”€ reach_env.py            # URReachEnv + ReachGymnasium
â”‚   â”‚   â””â”€â”€ slot_sorter_env.py      # URSlotSorterEnv + SlotSorterGymnasium
â”‚   â”œâ”€â”€ training/                   # RL training utilities
â”‚   â”‚   â”œâ”€â”€ callbacks.py            # BestEpisodeVideoCallback (SB3)
â”‚   â”‚   â”œâ”€â”€ train_reach.py          # PPO training for reach task
â”‚   â”‚   â””â”€â”€ train_slot_sorter.py    # PPO training for slot sorter
â”‚   â”œâ”€â”€ teleop/                     # Interactive controllers
â”‚   â”‚   â”œâ”€â”€ keyboard.py             # Keyboard teleop (both tasks)
â”‚   â”‚   â””â”€â”€ gamepad.py              # DualShock/DualSense gamepad
â”‚   â””â”€â”€ scripts/                    # CLI entry points
â”‚       â”œâ”€â”€ teleop.py               # Unified teleop launcher
â”‚       â”œâ”€â”€ train.py                # Unified training launcher
â”‚       â””â”€â”€ visual_smoke.py         # Scripted rollout video
â”œâ”€â”€ docs/images/                    # README screenshots
â”œâ”€â”€ pyproject.toml                  # Package metadata & dependencies
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## ğŸš€ Quick Start

### 1. Install dependencies

```bash
# Core (MuJoCo + Gymnasium)
pip install mujoco numpy gymnasium

# Training (optional)
pip install stable-baselines3 imageio[ffmpeg] tensorboard

# Gamepad (optional)
pip install pygame
```

Or install everything at once:

```bash
pip install -e ".[dev]"
```

### 2. Run teleop (keyboard)

```bash
# Reach task with UR5e
python scripts/teleop.py --task reach --robot ur5e

# Slot sorter
python scripts/teleop.py --task slot_sorter

# Slot sorter with gamepad
python scripts/teleop.py --task slot_sorter --gamepad
```

**Keyboard controls:**

| Key     | Action      |
|---------|-------------|
| W / S   | Â±Y movement |
| A / D   | Â±X movement |
| R / F   | Â±Z movement |
| Q / E   | Â±Yaw        |
| SPACE   | Grip toggle (slot sorter only) |
| X       | Emergency stop |

### 3. Train with PPO

```bash
# Reach task (default: Cartesian IK actions)
python scripts/train.py --task reach --robot ur5e --total-timesteps 500000

# Reach task (joint-space actions, Isaac Lab style)
python scripts/train.py --task reach --robot ur5e --action-mode joint --total-timesteps 500000

# Slot sorter
python scripts/train.py --task slot_sorter --total-timesteps 1000000

# Monitor in TensorBoard
tensorboard --logdir runs
```

### 4. Use as a Python library

```python
# Gymnasium API (compatible with SB3, CleanRL, etc.)
from mujoco_robot.envs import ReachGymnasium

env = ReachGymnasium(robot="ur5e")  # Cartesian IK (4-D actions)
# env = ReachGymnasium(robot="ur5e", action_mode="joint")  # Joint offsets (6-D)
obs, info = env.reset()

for _ in range(1000):
    action = env.action_space.sample()
    obs, reward, terminated, truncated, info = env.step(action)
    if terminated or truncated:
        obs, info = env.reset()

env.close()
```

```python
# Low-level API (for custom loops / teleop)
from mujoco_robot.envs import URReachEnv

env = URReachEnv(robot="ur3e", time_limit=0)
obs = env.reset()
result = env.step([0.5, 0.0, 0.0, 0.0])  # returns StepResult dataclass
print(f"EE pos: {result.info['ee_pos']}, dist: {result.info['dist']:.3f}")
```

---

## ğŸ–¼ï¸ Environments

### Reach Task

Move the end-effector to a random 3-D goal **position and yaw orientation** (red cube with RGB coordinate axes). The episode terminates when both the position and heading are matched, or on time-out.

| UR5e | UR3e |
|------|------|
| ![UR5e Reach](docs/images/reach_ur5e.png) | ![UR3e Reach](docs/images/reach_ur3e.png) |

### Slot Sorter Task

Pick up coloured objects and place them into matching slots.

<p align="center">
  <img src="docs/images/slot_sorter.png" alt="Slot Sorter Environment" width="60%"/>
</p>

---

## ğŸ—ï¸ Architecture

### Robot Models (dual-geom collision)

Each robot MJCF uses a **dual-geom architecture** for robust collision handling:

- **`viz` class** geoms â€” visual only (`contype=0`), provide the rendered appearance.
- **`col` class** geoms â€” collision only (`contype=1`), used for physics contacts.
- Only **6 adjacent body pairs** are excluded from collision (shoulderâ†”base, etc.).

### Environments

| Environment | Action Dim | Obs Dim | Description |
|-------------|-----------|---------|-------------|
| `URReachEnv` (cartesian) | 4 | 29 | Move EE to random 3-D pose (pos + yaw) via IK |
| `URReachEnv` (joint) | 6 | 31 | Move EE to random 3-D pose via joint offsets |
| `URSlotSorterEnv` | 5 | 71 | Pick colored objects â†’ matching slots |

Both environments use:
- **Position servo actuators** (kp=200) for stable joint control.
- **Damped-least-squares IK** for Cartesian end-effector commands.
- **Dense reward shaping** to help RL exploration.

### Core Modules

| Module | Purpose |
|--------|---------|
| `IKController` | Cartesian â†’ joint velocity via Jacobian pseudo-inverse |
| `CollisionDetector` | Counts non-adjacent robot link contacts |
| `xml_builder` | Programmatic MJCF injection (goals, cameras, etc.) |

---

## ğŸ§ª Running Tests

```bash
pytest tests/ -v
```

Expected: **14 tests**, all passing.

---

## ğŸ“Š Supported Robots

| Robot | Reach | Link Lengths Source |
|-------|-------|---------------------|
| UR5e  | ~0.85 m | Official UR ROS2 description |
| UR3e  | ~0.50 m | Official UR ROS2 description |

To add a new robot:
1. Create an MJCF XML in `mujoco_robot/robots/`.
2. Register it in `mujoco_robot/robots/configs.py` with a `RobotConfig` entry.

---

## ğŸ“¦ Dependencies

| Package | Version | Purpose |
|---------|---------|---------|
| `mujoco` | â‰¥ 3.1 | Physics simulation |
| `numpy` | any | Numerical computation |
| `gymnasium` | â‰¥ 1.0 | RL environment API |
| `stable-baselines3` | â‰¥ 2.0 | PPO training (optional) |
| `imageio` | any | Video recording (optional) |
| `pygame` | any | Gamepad input (optional) |

---

## ğŸ“ License

MIT
