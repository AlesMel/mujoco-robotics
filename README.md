# ğŸ¤– MuJoCo Robot â€” UR Arm RL Environments

Modular reinforcement-learning environments for **UR5e** and **UR3e** robot arms
in [MuJoCo](https://mujoco.readthedocs.io/), with [Gymnasium](https://gymnasium.farama.org/)
wrappers for training and keyboard/gamepad teleop for interactive testing.

---

## ğŸ“ Project Structure

```
mujoco-robot/
â”œâ”€â”€ mujoco_robot/                 # Main Python package
â”‚   â”œâ”€â”€ __init__.py               # Package root (version, top-level imports)
â”‚   â”œâ”€â”€ robots/                   # Robot models & configuration
â”‚   â”‚   â”œâ”€â”€ configs.py            # RobotConfig dataclass + registry
â”‚   â”‚   â”œâ”€â”€ ur5e.xml              # UR5e MJCF (dual-geom collision)
â”‚   â”‚   â””â”€â”€ ur3e.xml              # UR3e MJCF (dual-geom collision)
â”‚   â”œâ”€â”€ core/                     # Reusable engine modules
â”‚   â”‚   â”œâ”€â”€ ik_controller.py      # Damped-least-squares IK solver
â”‚   â”‚   â”œâ”€â”€ collision.py          # Self-collision detector
â”‚   â”‚   â””â”€â”€ xml_builder.py        # MJCF XML injection utilities
â”‚   â”œâ”€â”€ envs/                     # Gymnasium-ready environments
â”‚   â”‚   â”œâ”€â”€ reach_env.py          # URReachEnv + ReachGymnasium
â”‚   â”‚   â””â”€â”€ slot_sorter_env.py    # URSlotSorterEnv + SlotSorterGymnasium
â”‚   â”œâ”€â”€ training/                 # RL training utilities
â”‚   â”‚   â”œâ”€â”€ callbacks.py          # BestEpisodeVideoCallback (SB3)
â”‚   â”‚   â”œâ”€â”€ train_reach.py        # PPO training for reach task
â”‚   â”‚   â””â”€â”€ train_slot_sorter.py  # PPO training for slot sorter
â”‚   â””â”€â”€ teleop/                   # Interactive controllers
â”‚       â”œâ”€â”€ keyboard.py           # Keyboard teleop (both tasks)
â”‚       â””â”€â”€ gamepad.py            # DualShock/DualSense gamepad
â”œâ”€â”€ scripts/                      # CLI entry points
â”‚   â”œâ”€â”€ teleop.py                 # Unified teleop launcher
â”‚   â”œâ”€â”€ train.py                  # Unified training launcher
â”‚   â””â”€â”€ visual_smoke.py           # Scripted rollout video
â”œâ”€â”€ tests/                        # Pytest suite
â”‚   â”œâ”€â”€ test_reach_env.py         # 11 reach-env tests
â”‚   â””â”€â”€ test_slot_sorter.py       # 3 slot-sorter tests
â”œâ”€â”€ assets/                       # Original XML files (kept for reference)
â”œâ”€â”€ pyproject.toml                # Package metadata & dependencies
â””â”€â”€ README.md                     # This file
```

---

## ğŸš€ Quick Start

### 1. Install dependencies

```bash
# Core (MuJoCo + Gymnasium)
pip install mujoco numpy gymnasium

# Training (optional)
pip install stable-baselines3 imageio[ffmpeg] tensorboard

# Gamepad (optional)
pip install pygame
```

Or install everything at once:

```bash
pip install -e ".[dev]"
```

### 2. Run teleop (keyboard)

```bash
# Reach task with UR5e
python scripts/teleop.py --task reach --robot ur5e

# Slot sorter
python scripts/teleop.py --task slot_sorter

# Slot sorter with gamepad
python scripts/teleop.py --task slot_sorter --gamepad
```

**Keyboard controls:**

| Key     | Action      |
|---------|-------------|
| W / S   | Â±Y movement |
| A / D   | Â±X movement |
| R / F   | Â±Z movement |
| Q / E   | Â±Yaw        |
| SPACE   | Grip toggle (slot sorter only) |
| X       | Emergency stop |

### 3. Train with PPO

```bash
# Reach task
python scripts/train.py --task reach --robot ur5e --total-timesteps 500000

# Slot sorter
python scripts/train.py --task slot_sorter --total-timesteps 1000000

# Monitor in TensorBoard
tensorboard --logdir runs
```

### 4. Use as a Python library

```python
# Gymnasium API (compatible with SB3, CleanRL, etc.)
from mujoco_robot.envs import ReachGymnasium

env = ReachGymnasium(robot="ur5e")
obs, info = env.reset()

for _ in range(1000):
    action = env.action_space.sample()
    obs, reward, terminated, truncated, info = env.step(action)
    if terminated or truncated:
        obs, info = env.reset()

env.close()
```

```python
# Low-level API (for custom loops / teleop)
from mujoco_robot.envs import URReachEnv

env = URReachEnv(robot="ur3e", time_limit=0)
obs = env.reset()
result = env.step([0.5, 0.0, 0.0, 0.0])  # returns StepResult dataclass
print(f"EE pos: {result.info['ee_pos']}, dist: {result.info['dist']:.3f}")
```

---

## ğŸ—ï¸ Architecture

### Robot Models (dual-geom collision)

Each robot MJCF uses a **dual-geom architecture** for robust collision handling:

- **`viz` class** geoms â€” visual only (`contype=0`), provide the rendered appearance.
- **`col` class** geoms â€” collision only (`contype=1`), used for physics contacts.
- Only **6 adjacent body pairs** are excluded from collision (shoulderâ†”base, etc.).

### Environments

| Environment | Action Dim | Obs Dim | Description |
|-------------|-----------|---------|-------------|
| `URReachEnv` | 4 | 20 | Move EE to random 3-D goals |
| `URSlotSorterEnv` | 5 | 71 | Pick colored objects â†’ matching slots |

Both environments use:
- **Position servo actuators** (kp=200) for stable joint control.
- **Damped-least-squares IK** for Cartesian end-effector commands.
- **Dense reward shaping** to help RL exploration.

### Core Modules

| Module | Purpose |
|--------|---------|
| `IKController` | Cartesian â†’ joint velocity via Jacobian pseudo-inverse |
| `CollisionDetector` | Counts non-adjacent robot link contacts |
| `xml_builder` | Programmatic MJCF injection (goals, cameras, etc.) |

---

## ğŸ§ª Running Tests

```bash
pytest tests/ -v
```

Expected: **14 tests**, all passing.

---

## ğŸ“Š Supported Robots

| Robot | Reach | Link Lengths Source |
|-------|-------|---------------------|
| UR5e  | ~0.85 m | Official UR ROS2 description |
| UR3e  | ~0.50 m | Official UR ROS2 description |

To add a new robot:
1. Create an MJCF XML in `mujoco_robot/robots/`.
2. Register it in `mujoco_robot/robots/configs.py` with a `RobotConfig` entry.

---

## ğŸ“¦ Dependencies

| Package | Version | Purpose |
|---------|---------|---------|
| `mujoco` | â‰¥ 3.1 | Physics simulation |
| `numpy` | any | Numerical computation |
| `gymnasium` | â‰¥ 1.0 | RL environment API |
| `stable-baselines3` | â‰¥ 2.0 | PPO training (optional) |
| `imageio` | any | Video recording (optional) |
| `pygame` | any | Gamepad input (optional) |

---

## ğŸ“ License

MIT
